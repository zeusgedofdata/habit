{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e6b9ee-5391-457f-85cf-dfcd8acf0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_restful import Resource, Api, reqparse\n",
    "import pandas as pd\n",
    "import ast\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import requests\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "import json\n",
    "from multipledispatch import dispatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726f224a-92b7-4268-a5ae-09b777e3f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties():\n",
    "    props = {}\n",
    "    separator = \"=\"\n",
    "            \n",
    "    with open('./database.properties') as file:\n",
    "        for line in file: \n",
    "            if separator in line:\n",
    "                name, value = line.split(separator, 1)\n",
    "                props[name.strip()] = value.strip()\n",
    "    return props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c49243-9603-4436-b22f-a7231d26365b",
   "metadata": {},
   "source": [
    "### Setup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716e8549-c724-4f37-8bb2-889853d369a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self):\n",
    "        db_prop = get_properties()\n",
    "        self.username = db_prop.get('username')\n",
    "        self.password = db_prop.get('password')\n",
    "        self.host = db_prop.get('host')\n",
    "        self.port = db_prop.get('port')\n",
    "        self.database = db_prop.get('database')\n",
    "        #For SQLAlchemy\n",
    "       \n",
    "    \n",
    "    def connect(self):\n",
    "        connection = psycopg2.connect(user=self.username,\n",
    "                                      password=self.password,\n",
    "                                      host=self.host,\n",
    "                                      port=self.port,\n",
    "                                      database=self.database)\n",
    "        return connection, connection.cursor()\n",
    "    \n",
    "    def connect_alchemy(self):\n",
    "        '''Alt library to connect used for importing dataframes'''\n",
    "        engine = create_engine('postgresql://'+self.username+':'+self.password+'@'+self.host+':'+self.port+'/'+self.database)\n",
    "        return engine\n",
    "    \n",
    "    @dispatch(str)\n",
    "    def insert_habit(self, name):\n",
    "        query = 'INSERT INTO public.task (\"name\") VALUES (%s);'\n",
    "        values = tuple(name)\n",
    "        conn, cursor = None, None\n",
    "        try:\n",
    "            conn, cursor = self.connect()\n",
    "            cursor.execute(query, (name,))\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            # closing database connection.\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "    @dispatch(str, str)            \n",
    "    def insert_habit(self, name, date):\n",
    "        query = 'INSERT INTO public.task (\"name\", \"date\") VALUES (%s, %s);'\n",
    "        values = (name, date,)\n",
    "        conn, cursor, task_id = None, None, None\n",
    "        try:\n",
    "            conn, cursor = self.connect()\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "            ## BROKEN\n",
    "            task_id = cursor.fetchone()[0]\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            # closing database connection.\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return task_id\n",
    "        \n",
    "    def insert_dataframe(self, df):\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = self.connect_alchemy().connect()\n",
    "            df.to_sql('task', con=conn, if_exists='append', index=False)\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            # closing database connection.\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                \n",
    "    def insert_exercise(self, exercise):\n",
    "        query = \"\"\"INSERT INTO public.exercise (\"average_heart_rate\", \"calories\", \"duration\", \"steps\", \"distance\", \"task_fk\") \n",
    "        VALUES  (%s,%s, %s, %s, %s, %s);\"\"\"\n",
    "        conn, cursor = None, None\n",
    "        try:\n",
    "            conn, cursor = self.connect()\n",
    "            task_fk = sqlio.read_sql_query(\"select id from task where name = '\"+exercise['name']+\"' and date = '\"+exercise['date']+\"'\", conn)\n",
    "            if task_fk.empty:\n",
    "                task_fk = self.insert_habit(exercise['name'], exercise['date'])\n",
    "            \n",
    "            values = (exercise['avg_heart'],  exercise['calories'],  exercise['duration'],  exercise['steps'], exercise['distance'], int(task_fk['id'][0]))\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            # closing database connection.\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "    def insert_meditation(self, meditation):\n",
    "        query = \"\"\" INSERT into public.meditation (\"type\",\"duration\", task_fk) VALUES (%s, %s, %s)\"\"\"\n",
    "        con, cursor = None, None\n",
    "        try:\n",
    "            conn, cursor = self.connect()\n",
    "            task_fk = sqlio.read_sql_query(\"select id from task where name = 'Meditate' and date = '\"+meditation['date']+\"'\", conn)\n",
    "            if task_fk.empty:\n",
    "                task_fk = self.insert_habit('Meditate', meditation['date'])\n",
    "            values = (meditation['type'], meditation['duration'], int(task_fk['id'][0]))\n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            # closing database connection.\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "        \n",
    "    def read_habits(self):\n",
    "        query = \"select * from task\"\n",
    "        result = None\n",
    "        conn, cursor = None, None\n",
    "        try:\n",
    "            conn, cursor = self.connect()\n",
    "            result = sqlio.read_sql_query(query, conn)\n",
    "        except(Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while connecting to PostgreSQL\", error)\n",
    "        finally:\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return result         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1634c488-2542-4a45-b18a-c44f952f01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_conn_test():\n",
    "    db = Database()\n",
    "    db.insert_habit(\"test231\")\n",
    "    tables = db.read_habits()\n",
    "    return tables\n",
    "#db_conn_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab4d03-b64b-42ff-8777-fb1f0c64e82d",
   "metadata": {},
   "source": [
    "### Habitica Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661cbe05-a38d-4368-a82e-5685a7a78ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Habitica():\n",
    "    def __init__(self):\n",
    "        props = get_properties()\n",
    "        dataExport = \"https://habitica.com/api/v3/tasks/user\"\n",
    "        self.headers = {'x-client': props.get('x-client'),\n",
    "              'x-api-user': props.get('x-api-user'),\n",
    "              'x-api-key': props.get('x-api-key')}\n",
    "        request = requests.get(dataExport, headers = self.headers)\n",
    "        self.task_list = request.json()['data']\n",
    "        \n",
    "    def get_tasks(self):\n",
    "        ''' Get a list of all the tasks I'm tracking '''\n",
    "        tasks = [{'Name':task['text'], 'id':task['id']} for task in self.task_list if '#' not in task['text'] and 'Reward' not in task['text'] and task['type'] in 'daily' or 'habit']\n",
    "        cleaned = filter(lambda x: '##' not in x['Name'], tasks)\n",
    "        cleaned = filter(lambda x: 'Reward' not in x['Name'], cleaned)\n",
    "        return list(cleaned)\n",
    "    \n",
    "    def get_history(self):\n",
    "        '''Get a dataframe of the days I finished any tasks'''\n",
    "        task_hist_api = \"https://habitica.com/api/v3/tasks/\"\n",
    "        task_hist = []\n",
    "        #Get a list of the tasks we are tracking\n",
    "        tasks = self.get_tasks()\n",
    "        #Create a list of dataframes we will append to\n",
    "        df_list = [pd.DataFrame({'date', 'name'})]\n",
    "        # For each task loop through and grab the history of that task, \n",
    "        # then pull out only the relevent info for that task IE: did we do it that day\n",
    "        # Merge all the dataframes together and clean \n",
    "        for task in tasks:\n",
    "            response = requests.get(task_hist_api+task['id'], headers=self.headers).json()\n",
    "            df = pd.DataFrame(response['data']['history'])\n",
    "            df['name'] = task['Name']\n",
    "            rows_list = []\n",
    "            #df = df.dropna()\n",
    "            if df.columns[3] == 'completed':\n",
    "                ## Dailies\n",
    "                for index, row in df.iterrows():\n",
    "                    if index == 0 and row['value'] > 1:\n",
    "                        rows_list.append({'name': row['name'], 'date':pd.to_datetime(row['date'],unit='ms')})\n",
    "                    elif row['value'] > df.iloc[index - 1].value:\n",
    "                        rows_list.append({'name': row['name'], 'date':pd.to_datetime(row['date'],unit='ms')})\n",
    "            else:\n",
    "                #Habits\n",
    "                for index, row in df.iterrows():\n",
    "                    if row['scoredUp'] + row['scoredDown'] > 0:\n",
    "                        rows_list.append({'name': row['name'], 'date':pd.to_datetime(row['date'],unit='ms')})\n",
    "            #Create dataframe\n",
    "            df_list.append(pd.DataFrame(rows_list))\n",
    "        #Clean data\n",
    "        df_final = pd.concat(df_list)\n",
    "        df_final = df_final.drop([0], axis = 1)\n",
    "        df_final = df_final.sort_values(by = ['date'])\n",
    "        df_final['date'] = df_final['date'].dt.strftime('%Y-%m-%d')\n",
    "        df_final = df_final.reset_index()\n",
    "        df_final = df_final.drop(['index'], axis = 1)\n",
    "        df_final = df_final.dropna()\n",
    "        df_final = df_final[df_final.duplicated() == False]\n",
    "        return df_final\n",
    "    \n",
    "    def refresh_database(self):\n",
    "        db = Database()\n",
    "        tasks = self.get_history()\n",
    "        db.insert_dataframe(tasks)\n",
    "        \n",
    "\n",
    "#habitica = Habitica()\n",
    "#tasks = habitica.refresh_database()\n",
    "#tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee994462-2375-4007-a6a5-2883fa125f80",
   "metadata": {},
   "source": [
    "### Fit Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3855a787-b155-40dc-bcf1-3d64c183bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fit():\n",
    "    def __init__(self):\n",
    "        props = get_properties()\n",
    "        self.directory = Path(props['fit_file_location'])\n",
    "    \n",
    "    def read_exercise(self):\n",
    "        exercise_path = self.directory.joinpath('Physical Activity')\n",
    "        files = []\n",
    "        exercises = []\n",
    "        for entry in os.scandir(exercise_path):\n",
    "            if(\"exercise\" in str(entry)):\n",
    "                files.append(entry)  \n",
    "        for file in files:\n",
    "            with open(file) as exercise_file:\n",
    "                data = json.load(exercise_file)\n",
    "                exercises_data = [self.__load_run(exercise) for exercise in data if exercise['activityName'] in 'Run']\n",
    "                exercises_data = exercises_data + [self.__load_other(exercise) for exercise in data if exercise['activityName'] in 'Yoga']\n",
    "                exercises_data = exercises_data + [self.__load_other(exercise) for exercise in data if exercise['activityName'] in 'Weights']\n",
    "                exercises = exercises+exercises_data\n",
    "        return exercises\n",
    "    \n",
    "    def refresh_database(self):\n",
    "        db = Database()\n",
    "        exercises = self.read_exercise()\n",
    "        for exercise in exercises:\n",
    "            db.insert_exercise(exercise)\n",
    "        \n",
    "    \n",
    "    def __load_run(self, run):\n",
    "        run_simp = {\"name\":\"Run\", \"date\": pd.to_datetime(run['startTime']).strftime('%Y-%m-%d') , \"avg_heart\": run['averageHeartRate'], \"calories\":run['calories'], \"duration\": run['duration'], \"steps\": run['steps']}\n",
    "        if('distance' in run):\n",
    "            run_simp.update({\"distance\" : run['distance']})\n",
    "        else:\n",
    "            run_simp.update({\"distance\" : 0})\n",
    "        return run_simp\n",
    "    \n",
    "    def __load_other(self, other):\n",
    "        other_simp = {\"name\":other[\"activityName\"], \"date\": pd.to_datetime(other['startTime']).strftime('%Y-%m-%d') , \"calories\":other['calories'], \n",
    "                      \"duration\": other['duration'], \"avg_heart\": other['averageHeartRate'], \"steps\": 0, \"distance\":0}\n",
    "        return other_simp\n",
    "        \n",
    "    \n",
    "    \n",
    "#fit = Fit()\n",
    "#fit.read_exercise()\n",
    "#fit.refresh_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417f3af-ce00-4a39-8dae-443e7543e36d",
   "metadata": {},
   "source": [
    "### Waking up Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653b7a55-d440-462b-8902-7f43e62cb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakingUp():\n",
    "    def __init__(self):\n",
    "        props = get_properties()\n",
    "        self.directory = Path(props['wakingup_file_location'])\n",
    "        \n",
    "    def read_wakingup_file(self):\n",
    "        exercise_path = self.directory.joinpath('wu_progress.csv')\n",
    "        meditation_history = pd.read_csv(exercise_path, header=0, names=[\"date\", \"type\", \"duration\"])\n",
    "        meditation_history[\"date\"] = pd.to_datetime(meditation_history.date).dt.strftime('%Y-%m-%d') \n",
    "        return meditation_history\n",
    "    \n",
    "    def refresh_database(self):\n",
    "        db = Database()\n",
    "        meditations = self.read_wakingup_file()\n",
    "        for index, meditation in meditations.iterrows():\n",
    "            db.insert_meditation(meditation)\n",
    "        \n",
    "\n",
    "waking = WakingUp()\n",
    "#df = waking.read_wakingup_file()\n",
    "waking.refresh_database()\n",
    "#df['date']\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf85ac-e63f-4e8e-89de-39c4a3aa21ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecec2b-0ac0-4b17-9f15-16f42edd34b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64940f3-6b47-41a9-86dd-ece413167212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189d7e8-7b5e-4598-bdf5-162182593adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44a73a-f5d8-4575-b09c-35ed06ef41c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40dcd4b-f7a1-4827-9b8a-94022f7d207a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f931f0e-e206-4b7d-b4b1-a53b1064a5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73a3c7-8584-46d0-b626-1e1d3c0f563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ef26c-fd3d-4382-af31-e0f2a1bc2c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5024b-70d4-46d7-9e3f-d83c9b4bffa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa451f50-37e0-4503-b188-d0e6a3ff8bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
